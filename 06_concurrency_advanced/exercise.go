package main

import (
	"context"
	"fmt"
	"math/rand"
	"strings"
	"sync"
	"sync/atomic"
	"time"
)

// URL åˆ—è¡¨ï¼ˆæ¨¡æ‹Ÿè¦çˆ¬å–çš„ç½‘é¡µï¼‰
var urls = []string{
	"https://golang.org",
	"https://github.com",
	"https://google.com",
	"https://baidu.com",
	"https://zhihu.com",
	"https://bilibili.com",
	"https://taobao.com",
	"https://jd.com",
	"https://weibo.com",
	"https://douyin.com",
	"https://golang.org", // é‡å¤ï¼
	"https://github.com", // é‡å¤ï¼
	"https://example1.com",
	"https://example2.com",
	"https://example3.com",
}

type CrawlResult struct {
	URL      string
	Duration time.Duration
	Success  bool
}

func crawl(url string) CrawlResult {
	start := time.Now()

	// æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿï¼ˆ200-800msï¼‰
	delay := time.Duration(rand.Intn(600)+200) * time.Millisecond
	time.Sleep(delay)

	success := rand.Intn(10) > 0 // 90% æˆåŠŸç‡

	return CrawlResult{
		URL:      url,
		Duration: time.Since(start),
		Success:  success,
	}
}

func worker(id int, jobs <-chan string, results chan<- CrawlResult, wg *sync.WaitGroup, ctx context.Context) {
	defer wg.Done()

	for url := range jobs {
		select {
		case <-ctx.Done():
			fmt.Printf("Worker-%d: æ”¶åˆ°å–æ¶ˆä¿¡å·\n", id)
			return
		default:
			fmt.Printf("Worker-%d: çˆ¬å– %s\n", id, url)
			result := crawl(url)
			results <- result
		}
	}
}

func main() {
	rand.Seed(time.Now().UnixNano())

	fmt.Println("===== ä¸²è¡Œçˆ¬è™«ï¼ˆStep 1ï¼‰=====")
	start := time.Now()

	for _, url := range urls {
		result := crawl(url)
		if result.Success {
			fmt.Printf("æˆåŠŸçˆ¬å–: %s (è€—æ—¶: %v)\n", result.URL, result.Duration)
		} else {
			fmt.Printf("çˆ¬å–å¤±è´¥: %s (è€—æ—¶: %v)\n", result.URL, result.Duration)
		}
	}

	fmt.Printf("æ€»è€—æ—¶: %v\n\n", time.Since(start))

	// ä¿å­˜ä¸²è¡Œè€—æ—¶ç”¨äºåç»­å¯¹æ¯”
	serialDuration := time.Since(start)

	fmt.Println("===== å¹¶å‘çˆ¬è™«ï¼ˆStep 2ï¼‰=====")
	start = time.Now()

	// ä¸ºå¹¶å‘çˆ¬è™«åˆ›å»ºå¸¦10ç§’è¶…æ—¶çš„Context
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	jobs := make(chan string, 10)
	results := make(chan CrawlResult, 15)
	var wg sync.WaitGroup

	// Step 5: ä½¿ç”¨ atomic ç»Ÿè®¡æˆåŠŸ/å¤±è´¥/è·³è¿‡æ•°é‡
	var successCount, failCount, skippedCount int64

	// å¯åŠ¨ 5 ä¸ª worker
	for i := 1; i <= 5; i++ {
		wg.Add(1)
		go worker(i, jobs, results, &wg, ctx)
	}

	// å‘é€ä»»åŠ¡ï¼ˆå¸¦å»é‡ï¼‰
	go func() {
		visited := make(map[string]bool)

		for i, url := range urls {
			if visited[url] {
				fmt.Printf("â­ï¸  [%d] è·³è¿‡é‡å¤: %s\n", i+1, url)
				atomic.AddInt64(&skippedCount, 1)
				continue
			}
			visited[url] = true
			jobs <- url
		}
		close(jobs)
	}()

	// æ”¶é›†ç»“æœ
	go func() {
		wg.Wait()
		close(results)
	}()

	for result := range results {
		if result.Success {
			fmt.Printf("æˆåŠŸçˆ¬å–: %s (è€—æ—¶: %v)\n", result.URL, result.Duration)
			atomic.AddInt64(&successCount, 1)
		} else {
			fmt.Printf("çˆ¬å–å¤±è´¥: %s (è€—æ—¶: %v)\n", result.URL, result.Duration)
			atomic.AddInt64(&failCount, 1)
		}
	}

	// Step 5: æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
	concurrentDuration := time.Since(start)
	fmt.Println("\n" + strings.Repeat("=", 50))
	fmt.Println("ğŸ“Š å¹¶å‘çˆ¬è™«ç»Ÿè®¡æŠ¥å‘Š")
	fmt.Println(strings.Repeat("=", 50))
	fmt.Printf("âœ… æˆåŠŸ: %d ä¸ª\n", atomic.LoadInt64(&successCount))
	fmt.Printf("âŒ å¤±è´¥: %d ä¸ª\n", atomic.LoadInt64(&failCount))
	fmt.Printf("â­ï¸  è·³è¿‡: %d ä¸ª\n", atomic.LoadInt64(&skippedCount))
	fmt.Printf("ğŸ“ˆ æ€»è®¡: %d ä¸ªURL\n", len(urls))
	fmt.Printf("â±ï¸  ä¸²è¡Œè€—æ—¶: %v\n", serialDuration)
	fmt.Printf("âš¡ å¹¶å‘è€—æ—¶: %v\n", concurrentDuration)
	fmt.Printf("ğŸš€ æé€Ÿå€æ•°: %.2fx\n", float64(serialDuration)/float64(concurrentDuration))
	fmt.Println(strings.Repeat("=", 50))
}
